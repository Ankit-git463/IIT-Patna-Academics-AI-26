{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RfsjSNj4w_p",
        "outputId": "29db1827-98cf-4eff-e8e9-26324edc21da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Upload .tar file for Mahout and Spark on Google Drive\n",
        "# Mount same Drive account to Google Collab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y -qq openjdk-8-jdk-headless wget tar\n",
        "!apt install -y pigz > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d8t_E5_65N_6",
        "outputId": "f2044b40-c270-4ab5-eaaa-4ac111e35eab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "\n",
        "# drive_tar here is path for mahout tar file in Google drive (adjust accordingly)\n",
        "drive_tar = '/content/drive/MyDrive/apache-mahout-distribution-0.13.0.tar.gz'  # change this\n",
        "local_tar = '/content/apache-mahout-distribution-0.13.0.tar.gz'\n",
        "extract_dir = '/content/apache_mahout'\n",
        "\n",
        "# --- Copy from Drive  ---\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "print(\"Copying from Drive to Colab...\")\n",
        "subprocess.run([\"cp\", drive_tar, local_tar])\n",
        "\n",
        "# --- Step 1: Multi-threaded decompression ---\n",
        "print(\"Decompressing with 2 threads using pigz...\")\n",
        "subprocess.run([\"pigz\", \"-d\", \"-p\", \"2\", local_tar])\n",
        "\n",
        "# --- Step 2: Extract .tar ---\n",
        "tar_file = local_tar.replace(\".gz\", \"\")\n",
        "print(f\"Extracting {tar_file} to {extract_dir}...\")\n",
        "subprocess.run([\"tar\", \"-xf\", tar_file, \"-C\", extract_dir])\n",
        "\n",
        "print(f\"\\n✅ Extraction complete! Files are in: {extract_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZENM-9h357dD",
        "outputId": "dc7cbf97-10cb-441f-c8a1-5f3283f6c320"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying from Drive to Colab...\n",
            "Decompressing with 2 threads using pigz...\n",
            "Extracting /content/apache-mahout-distribution-0.13.0.tar to /content/apache_mahout...\n",
            "\n",
            "✅ Extraction complete! Files are in: /content/apache_mahout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "\n",
        "# drive_tar here is path for spark tar file in Google drive (adjust accordingly)\n",
        "drive_tar = '/content/drive/MyDrive/spark-2.2.0-bin-hadoop2.7.tgz'  # change this\n",
        "local_tar = '/content/spark-2.2.0-bin-hadoop2.7.tgz'\n",
        "extract_dir = '/content/spark'\n",
        "\n",
        "# --- Copy from Drive  ---\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "print(\"Copying from Drive to Colab...\")\n",
        "subprocess.run([\"cp\", drive_tar, local_tar])\n",
        "\n",
        "# --- Step 1: Multi-threaded decompression ---\n",
        "print(\"Decompressing with 2 threads using pigz...\")\n",
        "subprocess.run([\"pigz\", \"-d\", \"-p\", \"2\", local_tar])\n",
        "\n",
        "# --- Step 2: Extract .tar ---\n",
        "tar_file = local_tar.replace(\".gz\", \"\")\n",
        "print(f\"Extracting {tar_file} to {extract_dir}...\")\n",
        "subprocess.run([\"tar\", \"-xf\", tar_file, \"-C\", extract_dir])\n",
        "\n",
        "print(f\"\\n✅ Extraction complete! Files are in: {extract_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls0zh8F96p0_",
        "outputId": "38e28e05-8fe1-4ef8-aef0-e5965cc1c3c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying from Drive to Colab...\n",
            "Decompressing with 2 threads using pigz...\n",
            "Extracting /content/spark-2.2.0-bin-hadoop2.7.tgz to /content/spark...\n",
            "\n",
            "✅ Extraction complete! Files are in: /content/spark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#Run command to open scala shell\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['MAHOUT_HOME'] = '/content/apache_mahout/apache-mahout-distribution-0.13.0'\n",
        "os.environ['SPARK_HOME'] = '/content/spark/spark-2.2.0-bin-hadoop2.7'\n",
        "os.environ['PATH'] += f\":{os.environ['SPARK_HOME']}/bin\"\n",
        "\n",
        "!{os.environ['MAHOUT_HOME']}/bin/mahout spark-shell --master local[*] --driver-memory 2g\n",
        "\n",
        "#If it does not work run last 2 cells again"
      ],
      "metadata": {
        "id": "8yhNRIOtHOCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}